{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import shutil\n",
    "import inspect\n",
    "from nn_lib import *\n",
    "from train_procedures import *\n",
    "from train_utils import *\n",
    "from breakhis_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "np.random.seed(1997)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7908"
     ]
    }
   ],
   "source": [
    "data_set_total=load_breakhis_data(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_total=load_cifar100_data(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_hela10_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bf1d38af1cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhela10_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_hela10_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_hela10_data' is not defined"
     ]
    }
   ],
   "source": [
    "hela10_total=load_hela10_data(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_set_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d9f79641fc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_set_total' is not defined"
     ]
    }
   ],
   "source": [
    "data_set_total['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params={'beta':1e-5,\n",
    "              'initial_lr':0.1,\n",
    "              'train_batch_size':64,\n",
    "              'test_batch_size':64,\n",
    "              'lr_reduction_rate':10,\n",
    "              'lr_reduction_epoch':[4,7],\n",
    "              'use_fixedsize_exemplar':True,\n",
    "              'exemplar_set_size':1600,\n",
    "              'final_train_epochs':5,\n",
    "              'se':True,\n",
    "              'primary_exemplar':'svm_exemplar',\n",
    "              'train_method':'train_plain',\n",
    "              'sample_weight':1e-5,\n",
    "              'shuffle_class_ord':False,\n",
    "              'optimizer':'momentum',\n",
    "              'ewc_lambda':1e-5,\n",
    "              'loss_function':'softmax_cross_entropy_with_logits'}\n",
    "fixed_params={'dataset':'breakhis',\n",
    "              'net_type':'ResNet18',\n",
    "              'random_seed':1997,\n",
    "              'total_num_classes':8,\n",
    "              'base_dir':'./breakhis_temp',\n",
    "              'class_batch_size':2,\n",
    "              'use_theoretical_mean':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_total=dict(X_train=data_set_total['X_train'],\n",
    "                     Y_train=data_set_total['fine_labels_train'],\n",
    "                     X_test=data_set_total['X_test'],\n",
    "                     Y_test=data_set_total['fine_labels_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict_total=dict(X_train=cifar100_total['X_train'],\n",
    "#                      Y_train=cifar100_total['Y_train'],\n",
    "#                      X_test=cifar100_total['X_test'],\n",
    "#                      Y_test=cifar100_total['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_prob\n",
      "log_prob\n",
      "log_prob\n"
     ]
    }
   ],
   "source": [
    "tf_tensors,tf_variables,tf_networks=build_graph(hyper_params,fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "sess=tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_dir': './breakhis_temp',\n",
      " 'class_batch_size': 2,\n",
      " 'dataset': 'breakhis',\n",
      " 'net_type': 'ResNet18',\n",
      " 'random_seed': 1997,\n",
      " 'total_num_classes': 8,\n",
      " 'use_theoretical_mean': True}\n",
      "{'beta': 1e-05,\n",
      " 'ewc_lambda': 1,\n",
      " 'exemplar_set_size': 1600,\n",
      " 'final_train_epochs': 5,\n",
      " 'initial_lr': 0.001,\n",
      " 'loss_function': 'softmax_cross_entropy_with_logits',\n",
      " 'lr_reduction_epoch': [10, 20, 30],\n",
      " 'lr_reduction_rate': 5,\n",
      " 'optimizer': 'momentum',\n",
      " 'primary_exemplar': 'svm_exemplar',\n",
      " 'sample_weight': 1,\n",
      " 'se': True,\n",
      " 'shuffle_class_ord': False,\n",
      " 'test_batch_size': 64,\n",
      " 'train_batch_size': 64,\n",
      " 'train_method': 'train_plain',\n",
      " 'use_fixedsize_exemplar': True}\n",
      "./breakhis_temp already exists, override?y\n",
      "data_dict_current: 5074\n",
      "Counter({0: 2537, 1: 2537})\n",
      "data_dict_current_weight:\n",
      "Counter({1: 5074})\n",
      "data_dict_total: 400\n",
      "Counter({0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50, 7: 50})\n",
      "===========Iteration 1=============\n",
      "Using classes [0, 1]\n",
      "augmentation: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation: 2\n",
      "Class batch pretrain evaluation (plain method)\n",
      "\tTrain loss: 2.113902\n",
      "\tTrain class loss: 2.057072\n",
      "\tTrain reg loss: 0.000000\n",
      "\tValidation loss: 2.114996\n",
      "\tValidation class loss: 2.058166\n",
      "\tValidation reg loss: 0.056830\n",
      "\tTop1 train accuracy: 0.000000\n",
      "\tTop5 train accuracy: 0.512022\n",
      "\tTop1 validation accuracy: 0.000000\n",
      "\tTop5 validation accuracy: 0.500000\n",
      "[[ 0  0 50]\n",
      " [ 0  0 50]\n",
      " [ 0  0  0]]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Epoch 1\n",
      "\tTrain loss: 0.603844\n",
      "\tTrain class loss: 0.547012\n",
      "\tTrain reg loss: 0.056832\n",
      "\tValidation loss: 0.636160\n",
      "\tValidation class loss: 0.579326\n",
      "\tValidation reg loss: 0.056834\n",
      "\tTop1 train accuracy: 0.787579\n",
      "\tTop5 train accuracy: 0.970926\n",
      "\tTop1 validation accuracy: 0.810000\n",
      "\tTop5 validation accuracy: 0.990000\n",
      "[[36 14]\n",
      " [ 5 45]]\n",
      "network nan test after epoch\n",
      "mbi=4366983680\n",
      "epoch 1, global step 1, time 99.957123\n",
      "saving model parameters...\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "On iteration 1\n",
      "Plain evaluation before retrain\n",
      "\tBest top1 validation accuracy: 0.810000\n",
      "\tBest top5 validation accuracy: 0.990000\n",
      "\tBest top1 cumul accuracy: 0.810000\n",
      "\tBest top5 cumul accuracy: 0.990000\n",
      "\tBest top1 ori accuracy: 0.810000\n",
      "\tBest top5 ori accuracy: 0.990000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.72      0.79        50\n",
      "          1       0.76      0.90      0.83        50\n",
      "\n",
      "avg / total       0.82      0.81      0.81       100\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "here\n",
      "augmentation: 2\n",
      "971 support_vectors for class 0\n",
      "968 support_vectors for class 1\n",
      "augmentation: 2\n",
      "retraining last layer\n",
      "Epoch 1\n",
      "augmentation: 2\n",
      "Epoch 2\n",
      "augmentation: 2\n",
      "Epoch 3\n",
      "augmentation: 2\n",
      "Epoch 4\n",
      "augmentation: 2\n",
      "Epoch 5\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Plain evaluation after retrain\n",
      "\tBest top1 validation accuracy: 0.820000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.820000\n",
      "\tBest top5 cumul accuracy: 1.000000\n",
      "\tBest top1 ori accuracy: 0.820000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.96      0.84        50\n",
      "          1       0.94      0.68      0.79        50\n",
      "\n",
      "avg / total       0.85      0.82      0.82       100\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "SVM evaluation\n",
      "\tBest top1 validation accuracy: 0.960000\n",
      "\tBest top1 cumul accuracy: 0.960000\n",
      "\tBest top1 ori accuracy: 0.960000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        50\n",
      "          1       1.00      0.92      0.96        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       100\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Exemplar mean evaluation\n",
      "\tBest top1 validation accuracy: 0.800000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.800000\n",
      "\tBest top5 cumul accuracy: 1.000000\n",
      "\tBest top1 ori accuracy: 0.800000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.92      0.82        50\n",
      "          1       0.89      0.68      0.77        50\n",
      "\n",
      "avg / total       0.82      0.80      0.80       100\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Theoretical mean evaluation\n",
      "\tBest top1 validation accuracy: 0.800000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.800000\n",
      "\tBest top5 cumul accuracy: 1.000000\n",
      "\tBest top1 ori accuracy: 0.800000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.92      0.82        50\n",
      "          1       0.89      0.68      0.77        50\n",
      "\n",
      "avg / total       0.82      0.80      0.80       100\n",
      "\n",
      "computing fisher information\n",
      "augmentation: 2\n",
      "conv_1/W:2.855743e+02\n",
      "batch_norm_1/scale:5.510414e+00\n",
      "resconv1_2a/W:1.665227e+00\n",
      "batch_norm_resconv1_2a/scale:3.708243e-01\n",
      "resconv2_2a/W:1.451223e+00\n",
      "batch_norm_resconv2_2a/scale:1.732863e-01\n",
      "squeeze_excitation_2a/fc1/W:4.537653e-04\n",
      "squeeze_excitation_2a/fc2/W:7.797407e-04\n",
      "resconv1_2b/W:1.673374e+00\n",
      "batch_norm_resconv1_2b/scale:6.029138e-01\n",
      "resconv2_2b/W:7.756915e-01\n",
      "batch_norm_resconv2_2b/scale:2.046949e-01\n",
      "squeeze_excitation_2b/fc1/W:2.273003e-04\n",
      "squeeze_excitation_2b/fc2/W:1.085957e-03\n",
      "resconv1_3a/W:6.614670e-02\n",
      "batch_norm_resconv1_3a/scale:1.333206e-02\n",
      "resconv2_3a/W:8.168462e-02\n",
      "batch_norm_resconv2_3a/scale:2.436852e-02\n",
      "squeeze_excitation_3a/fc1/W:5.805461e-05\n",
      "squeeze_excitation_3a/fc2/W:2.811245e-04\n",
      "projconv_3a/W:1.764603e+00\n",
      "batch_norm_projconv_3a/scale:1.714935e-01\n",
      "resconv1_3b/W:4.753652e-02\n",
      "batch_norm_resconv1_3b/scale:1.728411e-02\n",
      "resconv2_3b/W:6.476101e-02\n",
      "batch_norm_resconv2_3b/scale:5.132493e-03\n",
      "squeeze_excitation_3b/fc1/W:2.293637e-05\n",
      "squeeze_excitation_3b/fc2/W:1.160355e-04\n",
      "resconv1_4a/W:1.635977e-02\n",
      "batch_norm_resconv1_4a/scale:3.530701e-03\n",
      "resconv2_4a/W:2.266649e-02\n",
      "batch_norm_resconv2_4a/scale:5.727206e-03\n",
      "squeeze_excitation_4a/fc1/W:1.307227e-05\n",
      "squeeze_excitation_4a/fc2/W:1.172770e-04\n",
      "projconv_4a/W:1.181176e-01\n",
      "batch_norm_projconv_4a/scale:3.324952e-02\n",
      "resconv1_4b/W:1.087534e-02\n",
      "batch_norm_resconv1_4b/scale:3.189617e-03\n",
      "resconv2_4b/W:2.070687e-02\n",
      "batch_norm_resconv2_4b/scale:4.449791e-03\n",
      "squeeze_excitation_4b/fc1/W:1.465558e-05\n",
      "squeeze_excitation_4b/fc2/W:1.432388e-04\n",
      "resconv1_5a/W:6.374279e-03\n",
      "batch_norm_resconv1_5a/scale:1.173655e-03\n",
      "resconv2_5a/W:3.622257e-03\n",
      "batch_norm_resconv2_5a/scale:5.791022e-04\n",
      "squeeze_excitation_5a/fc1/W:7.349230e-06\n",
      "squeeze_excitation_5a/fc2/W:2.592500e-05\n",
      "projconv_5a/W:4.140329e-02\n",
      "batch_norm_projconv_5a/scale:6.936919e-03\n",
      "resconv1_5b/W:5.814231e-03\n",
      "batch_norm_resconv1_5b/scale:2.364821e-03\n",
      "resconv2_5b/W:2.215204e-03\n",
      "batch_norm_resconv2_5b/scale:3.126571e-04\n",
      "squeeze_excitation_5b/fc1/W:8.461196e-06\n",
      "squeeze_excitation_5b/fc2/W:1.555769e-05\n",
      "fc/W:2.036177e-01\n",
      "fisher_nan_test\n",
      "data_dict_current: 6674\n",
      "Counter({2: 2537, 3: 2537, 0: 800, 1: 800})\n",
      "data_dict_current_weight:\n",
      "Counter({1: 5074})\n",
      "data_dict_total: 400\n",
      "Counter({0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50, 7: 50})\n",
      "===========Iteration 2=============\n",
      "Using classes [2, 3]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Class batch pretrain evaluation (plain method)\n",
      "\tTrain loss: 6.261413\n",
      "\tTrain class loss: 6.204579\n",
      "\tTrain reg loss: 0.120917\n",
      "\tValidation loss: 7.739509\n",
      "\tValidation class loss: 7.682675\n",
      "\tValidation reg loss: 0.056834\n",
      "\tTop1 train accuracy: 0.120917\n",
      "\tTop5 train accuracy: 0.761013\n",
      "\tTop1 validation accuracy: 0.000000\n",
      "\tTop5 validation accuracy: 0.680000\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 6 44  0  0]\n",
      " [15 35  0  0]]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Epoch 1\n",
      "\tTrain loss: 1.241454\n",
      "\tTrain class loss: 1.137067\n",
      "\tTrain reg loss: 0.056830\n",
      "\tValidation loss: 3.190962\n",
      "\tValidation class loss: 3.097686\n",
      "\tValidation reg loss: 0.056831\n",
      "\tTop1 train accuracy: 0.652194\n",
      "\tTop5 train accuracy: 0.987530\n",
      "\tTop1 validation accuracy: 0.510000\n",
      "\tTop5 validation accuracy: 0.990000\n",
      "[[50  0]\n",
      " [49  1]]\n",
      "network nan test after epoch\n",
      "mbi=4392602880\n",
      "epoch 1, global step 2, time 133.667627\n",
      "saving model parameters...\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "On iteration 2\n",
      "Plain evaluation before retrain\n",
      "\tBest top1 validation accuracy: 0.510000\n",
      "\tBest top5 validation accuracy: 0.990000\n",
      "\tBest top1 cumul accuracy: 0.265000\n",
      "\tBest top5 cumul accuracy: 0.890000\n",
      "\tBest top1 ori accuracy: 0.020000\n",
      "\tBest top5 ori accuracy: 0.790000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.08        50\n",
      "          1       0.00      0.00      0.00        50\n",
      "          2       0.26      1.00      0.42        50\n",
      "          3       0.11      0.02      0.03        50\n",
      "\n",
      "avg / total       0.34      0.27      0.13       200\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "here\n",
      "augmentation: 2\n",
      "1023 support_vectors for class 0\n",
      "2118 support_vectors for class 1\n",
      "1461 support_vectors for class 2\n",
      "1915 support_vectors for class 3\n",
      "augmentation: 2\n",
      "retraining last layer\n",
      "Epoch 1\n",
      "augmentation: 2\n",
      "Epoch 2\n",
      "augmentation: 2\n",
      "Epoch 3\n",
      "augmentation: 2\n",
      "Epoch 4\n",
      "augmentation: 2\n",
      "Epoch 5\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Plain evaluation after retrain\n",
      "\tBest top1 validation accuracy: 0.380000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.345000\n",
      "\tBest top5 cumul accuracy: 1.000000\n",
      "\tBest top1 ori accuracy: 0.310000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        50\n",
      "          1       0.27      0.52      0.35        50\n",
      "          2       0.41      0.76      0.53        50\n",
      "          3       0.00      0.00      0.00        50\n",
      "\n",
      "avg / total       0.42      0.34      0.27       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "SVM evaluation\n",
      "\tBest top1 validation accuracy: 0.780000\n",
      "\tBest top1 cumul accuracy: 0.670000\n",
      "\tBest top1 ori accuracy: 0.560000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.98      0.86        50\n",
      "          1       0.88      0.14      0.24        50\n",
      "          2       0.58      0.86      0.69        50\n",
      "          3       0.65      0.70      0.67        50\n",
      "\n",
      "avg / total       0.72      0.67      0.62       200\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Exemplar mean evaluation\n",
      "\tBest top1 validation accuracy: 0.560000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.575000\n",
      "\tBest top5 cumul accuracy: 1.000000\n",
      "\tBest top1 ori accuracy: 0.590000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.88      0.81        50\n",
      "          1       0.38      0.30      0.34        50\n",
      "          2       0.55      0.56      0.55        50\n",
      "          3       0.54      0.56      0.55        50\n",
      "\n",
      "avg / total       0.56      0.57      0.56       200\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Theoretical mean evaluation\n",
      "\tBest top1 validation accuracy: 0.580000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.585000\n",
      "\tBest top5 cumul accuracy: 1.000000\n",
      "\tBest top1 ori accuracy: 0.590000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.88      0.81        50\n",
      "          1       0.41      0.30      0.34        50\n",
      "          2       0.57      0.60      0.58        50\n",
      "          3       0.54      0.56      0.55        50\n",
      "\n",
      "avg / total       0.57      0.58      0.57       200\n",
      "\n",
      "computing fisher information\n",
      "augmentation: 2\n",
      "conv_1/W:1.270982e+02\n",
      "batch_norm_1/scale:8.470376e-01\n",
      "resconv1_2a/W:1.186875e+00\n",
      "batch_norm_resconv1_2a/scale:3.634543e-01\n",
      "resconv2_2a/W:1.135302e+00\n",
      "batch_norm_resconv2_2a/scale:2.718675e-01\n",
      "squeeze_excitation_2a/fc1/W:1.308842e-03\n",
      "squeeze_excitation_2a/fc2/W:1.416213e-03\n",
      "resconv1_2b/W:3.862159e-01\n",
      "batch_norm_resconv1_2b/scale:1.301100e-01\n",
      "resconv2_2b/W:1.196483e-01\n",
      "batch_norm_resconv2_2b/scale:5.053711e-02\n",
      "squeeze_excitation_2b/fc1/W:7.605096e-05\n",
      "squeeze_excitation_2b/fc2/W:2.343151e-04\n",
      "resconv1_3a/W:3.117506e-02\n",
      "batch_norm_resconv1_3a/scale:1.983484e-02\n",
      "resconv2_3a/W:3.122775e-02\n",
      "batch_norm_resconv2_3a/scale:1.116096e-02\n",
      "squeeze_excitation_3a/fc1/W:1.104990e-05\n",
      "squeeze_excitation_3a/fc2/W:1.050718e-04\n",
      "projconv_3a/W:2.811956e-01\n",
      "batch_norm_projconv_3a/scale:5.865186e-02\n",
      "resconv1_3b/W:3.118258e-02\n",
      "batch_norm_resconv1_3b/scale:7.781007e-03\n",
      "resconv2_3b/W:2.084176e-02\n",
      "batch_norm_resconv2_3b/scale:3.164962e-03\n",
      "squeeze_excitation_3b/fc1/W:1.523864e-05\n",
      "squeeze_excitation_3b/fc2/W:3.303143e-05\n",
      "resconv1_4a/W:1.487682e-02\n",
      "batch_norm_resconv1_4a/scale:6.748941e-03\n",
      "resconv2_4a/W:1.032219e-02\n",
      "batch_norm_resconv2_4a/scale:1.742156e-03\n",
      "squeeze_excitation_4a/fc1/W:2.069238e-05\n",
      "squeeze_excitation_4a/fc2/W:3.306903e-05\n",
      "projconv_4a/W:4.973345e-02\n",
      "batch_norm_projconv_4a/scale:7.019799e-03\n",
      "resconv1_4b/W:5.733583e-03\n",
      "batch_norm_resconv1_4b/scale:1.447768e-03\n",
      "resconv2_4b/W:2.628239e-03\n",
      "batch_norm_resconv2_4b/scale:8.828117e-04\n",
      "squeeze_excitation_4b/fc1/W:5.890540e-06\n",
      "squeeze_excitation_4b/fc2/W:1.461072e-05\n",
      "resconv1_5a/W:1.077580e-03\n",
      "batch_norm_resconv1_5a/scale:1.869626e-04\n",
      "resconv2_5a/W:1.010819e-03\n",
      "batch_norm_resconv2_5a/scale:7.166936e-05\n",
      "squeeze_excitation_5a/fc1/W:9.078744e-07\n",
      "squeeze_excitation_5a/fc2/W:2.892859e-06\n",
      "projconv_5a/W:8.785598e-03\n",
      "batch_norm_projconv_5a/scale:9.663184e-04\n",
      "resconv1_5b/W:1.715113e-03\n",
      "batch_norm_resconv1_5b/scale:5.352665e-04\n",
      "resconv2_5b/W:4.081338e-04\n",
      "batch_norm_resconv2_5b/scale:5.724619e-05\n",
      "squeeze_excitation_5b/fc1/W:8.307142e-07\n",
      "squeeze_excitation_5b/fc2/W:1.187618e-06\n",
      "fc/W:4.215391e-02\n",
      "fisher_nan_test\n",
      "data_dict_current: 6674\n",
      "Counter({4: 2537, 5: 2537, 0: 400, 1: 400, 2: 400, 3: 400})\n",
      "data_dict_current_weight:\n",
      "Counter({1: 5074})\n",
      "data_dict_total: 400\n",
      "Counter({0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50, 7: 50})\n",
      "===========Iteration 3=============\n",
      "Using classes [4, 5]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Class batch pretrain evaluation (plain method)\n",
      "\tTrain loss: 10.072874\n",
      "\tTrain class loss: 10.016044\n",
      "\tTrain reg loss: 0.060384\n",
      "\tValidation loss: 11.361008\n",
      "\tValidation class loss: 11.304178\n",
      "\tValidation reg loss: 0.056831\n",
      "\tTop1 train accuracy: 0.060384\n",
      "\tTop5 train accuracy: 0.399161\n",
      "\tTop1 validation accuracy: 0.000000\n",
      "\tTop5 validation accuracy: 0.260000\n",
      "[[ 0  0  0]\n",
      " [50  0  0]\n",
      " [50  0  0]]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Epoch 1\n",
      "\tTrain loss: 1.284723\n",
      "\tTrain class loss: 1.190153\n",
      "\tTrain reg loss: 0.056828\n",
      "\tValidation loss: 0.464730\n",
      "\tValidation class loss: 0.386643\n",
      "\tValidation reg loss: 0.056828\n",
      "\tTop1 train accuracy: 0.620793\n",
      "\tTop5 train accuracy: 0.951022\n",
      "\tTop1 validation accuracy: 0.850000\n",
      "\tTop5 validation accuracy: 1.000000\n",
      "[[35 15]\n",
      " [ 0 50]]\n",
      "network nan test after epoch\n",
      "mbi=4480403200\n",
      "epoch 1, global step 3, time 133.182557\n",
      "saving model parameters...\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "On iteration 3\n",
      "Plain evaluation before retrain\n",
      "\tBest top1 validation accuracy: 0.850000\n",
      "\tBest top5 validation accuracy: 1.000000\n",
      "\tBest top1 cumul accuracy: 0.396667\n",
      "\tBest top5 cumul accuracy: 0.963333\n",
      "\tBest top1 ori accuracy: 0.180000\n",
      "\tBest top5 ori accuracy: 0.940000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.36      0.34        50\n",
      "          1       0.00      0.00      0.00        50\n",
      "          2       0.41      0.32      0.36        50\n",
      "          3       0.00      0.00      0.00        50\n",
      "          4       0.49      0.70      0.58        50\n",
      "          5       0.38      1.00      0.55        50\n",
      "\n",
      "avg / total       0.27      0.40      0.30       300\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "here\n",
      "augmentation: 2\n",
      "1551 support_vectors for class 0\n",
      "2407 support_vectors for class 1\n",
      "1920 support_vectors for class 2\n",
      "2218 support_vectors for class 3\n",
      "1603 support_vectors for class 4\n",
      "1336 support_vectors for class 5\n",
      "augmentation: 2\n",
      "retraining last layer\n",
      "Epoch 1\n",
      "augmentation: 2\n",
      "Epoch 2\n",
      "augmentation: 2\n",
      "Epoch 3\n",
      "augmentation: 2\n",
      "Epoch 4\n",
      "augmentation: 2\n",
      "Epoch 5\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Plain evaluation after retrain\n",
      "\tBest top1 validation accuracy: 0.570000\n",
      "\tBest top5 validation accuracy: 0.920000\n",
      "\tBest top1 cumul accuracy: 0.463333\n",
      "\tBest top5 cumul accuracy: 0.970000\n",
      "\tBest top1 ori accuracy: 0.460000\n",
      "\tBest top5 ori accuracy: 0.990000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.92      0.53        50\n",
      "          1       0.00      0.00      0.00        50\n",
      "          2       0.37      0.72      0.49        50\n",
      "          3       0.00      0.00      0.00        50\n",
      "          4       0.74      0.50      0.60        50\n",
      "          5       0.74      0.64      0.69        50\n",
      "\n",
      "avg / total       0.37      0.46      0.38       300\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "SVM evaluation\n",
      "\tBest top1 validation accuracy: 0.810000\n",
      "\tBest top1 cumul accuracy: 0.570000\n",
      "\tBest top1 ori accuracy: 0.460000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.78      0.68        50\n",
      "          1       0.88      0.14      0.24        50\n",
      "          2       0.49      0.50      0.50        50\n",
      "          3       0.53      0.38      0.44        50\n",
      "          4       0.55      0.68      0.61        50\n",
      "          5       0.59      0.94      0.73        50\n",
      "\n",
      "avg / total       0.61      0.57      0.53       300\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Exemplar mean evaluation\n",
      "\tBest top1 validation accuracy: 0.760000\n",
      "\tBest top5 validation accuracy: 0.980000\n",
      "\tBest top1 cumul accuracy: 0.536667\n",
      "\tBest top5 cumul accuracy: 0.990000\n",
      "\tBest top1 ori accuracy: 0.400000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.58      0.60        50\n",
      "          1       0.32      0.22      0.26        50\n",
      "          2       0.49      0.46      0.47        50\n",
      "          3       0.46      0.44      0.45        50\n",
      "          4       0.59      0.64      0.62        50\n",
      "          5       0.62      0.88      0.73        50\n",
      "\n",
      "avg / total       0.52      0.54      0.52       300\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Theoretical mean evaluation\n",
      "\tBest top1 validation accuracy: 0.760000\n",
      "\tBest top5 validation accuracy: 0.980000\n",
      "\tBest top1 cumul accuracy: 0.536667\n",
      "\tBest top5 cumul accuracy: 0.990000\n",
      "\tBest top1 ori accuracy: 0.400000\n",
      "\tBest top5 ori accuracy: 1.000000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.58      0.59        50\n",
      "          1       0.33      0.22      0.27        50\n",
      "          2       0.49      0.46      0.47        50\n",
      "          3       0.48      0.44      0.46        50\n",
      "          4       0.59      0.64      0.62        50\n",
      "          5       0.62      0.88      0.73        50\n",
      "\n",
      "avg / total       0.52      0.54      0.52       300\n",
      "\n",
      "computing fisher information\n",
      "augmentation: 2\n",
      "conv_1/W:2.603281e+01\n",
      "batch_norm_1/scale:2.938816e-01\n",
      "resconv1_2a/W:2.506683e-01\n",
      "batch_norm_resconv1_2a/scale:4.944172e-02\n",
      "resconv2_2a/W:2.544680e-01\n",
      "batch_norm_resconv2_2a/scale:8.759464e-02\n",
      "squeeze_excitation_2a/fc1/W:1.204127e-04\n",
      "squeeze_excitation_2a/fc2/W:4.610404e-04\n",
      "resconv1_2b/W:1.075426e-01\n",
      "batch_norm_resconv1_2b/scale:5.797332e-02\n",
      "resconv2_2b/W:1.113472e-01\n",
      "batch_norm_resconv2_2b/scale:4.446607e-02\n",
      "squeeze_excitation_2b/fc1/W:5.533143e-05\n",
      "squeeze_excitation_2b/fc2/W:3.883042e-04\n",
      "resconv1_3a/W:6.655097e-02\n",
      "batch_norm_resconv1_3a/scale:1.134090e-02\n",
      "resconv2_3a/W:2.810402e-02\n",
      "batch_norm_resconv2_3a/scale:6.800459e-03\n",
      "squeeze_excitation_3a/fc1/W:3.333079e-05\n",
      "squeeze_excitation_3a/fc2/W:3.868279e-04\n",
      "projconv_3a/W:2.312220e-01\n",
      "batch_norm_projconv_3a/scale:6.248206e-02\n",
      "resconv1_3b/W:2.348514e-02\n",
      "batch_norm_resconv1_3b/scale:5.933545e-03\n",
      "resconv2_3b/W:2.922648e-02\n",
      "batch_norm_resconv2_3b/scale:3.683098e-03\n",
      "squeeze_excitation_3b/fc1/W:2.369096e-05\n",
      "squeeze_excitation_3b/fc2/W:4.928448e-05\n",
      "resconv1_4a/W:1.204609e-02\n",
      "batch_norm_resconv1_4a/scale:2.536391e-03\n",
      "resconv2_4a/W:1.765504e-02\n",
      "batch_norm_resconv2_4a/scale:2.428568e-03\n",
      "squeeze_excitation_4a/fc1/W:1.390304e-05\n",
      "squeeze_excitation_4a/fc2/W:9.126874e-05\n",
      "projconv_4a/W:1.203766e-01\n",
      "batch_norm_projconv_4a/scale:1.445043e-02\n",
      "resconv1_4b/W:2.505947e-02\n",
      "batch_norm_resconv1_4b/scale:3.110652e-03\n",
      "resconv2_4b/W:2.328241e-02\n",
      "batch_norm_resconv2_4b/scale:4.720792e-03\n",
      "squeeze_excitation_4b/fc1/W:2.596911e-05\n",
      "squeeze_excitation_4b/fc2/W:4.105338e-05\n",
      "resconv1_5a/W:8.945846e-03\n",
      "batch_norm_resconv1_5a/scale:1.391638e-03\n",
      "resconv2_5a/W:4.948769e-03\n",
      "batch_norm_resconv2_5a/scale:5.181706e-04\n",
      "squeeze_excitation_5a/fc1/W:1.098944e-05\n",
      "squeeze_excitation_5a/fc2/W:1.994744e-05\n",
      "projconv_5a/W:6.086750e-02\n",
      "batch_norm_projconv_5a/scale:5.238722e-03\n",
      "resconv1_5b/W:1.213100e-02\n",
      "batch_norm_resconv1_5b/scale:2.133189e-03\n",
      "resconv2_5b/W:2.717301e-03\n",
      "batch_norm_resconv2_5b/scale:4.666637e-04\n",
      "squeeze_excitation_5b/fc1/W:6.523446e-06\n",
      "squeeze_excitation_5b/fc2/W:1.559863e-05\n",
      "fc/W:1.938769e-01\n",
      "fisher_nan_test\n",
      "data_dict_current: 6670\n",
      "Counter({6: 2537, 7: 2537, 0: 266, 1: 266, 2: 266, 3: 266, 4: 266, 5: 266})\n",
      "data_dict_current_weight:\n",
      "Counter({1: 5074})\n",
      "data_dict_total: 400\n",
      "Counter({0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50, 7: 50})\n",
      "===========Iteration 4=============\n",
      "Using classes [6, 7]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Class batch pretrain evaluation (plain method)\n",
      "\tTrain loss: 5.471820\n",
      "\tTrain class loss: 5.414992\n",
      "\tTrain reg loss: 0.084708\n",
      "\tValidation loss: 6.620364\n",
      "\tValidation class loss: 6.563536\n",
      "\tValidation reg loss: 0.056828\n",
      "\tTop1 train accuracy: 0.084708\n",
      "\tTop5 train accuracy: 0.245427\n",
      "\tTop1 validation accuracy: 0.000000\n",
      "\tTop5 validation accuracy: 0.010000\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 2  1  8 39  0  0]\n",
      " [ 1  0 25 24  0  0]]\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Epoch 1\n",
      "\tTrain loss: 1.484971\n",
      "\tTrain class loss: 1.395060\n",
      "\tTrain reg loss: 0.056825\n",
      "\tValidation loss: 2.854715\n",
      "\tValidation class loss: 2.772501\n",
      "\tValidation reg loss: 0.056824\n",
      "\tTop1 train accuracy: 0.596454\n",
      "\tTop5 train accuracy: 0.906851\n",
      "\tTop1 validation accuracy: 0.520000\n",
      "\tTop5 validation accuracy: 0.700000\n",
      "[[50  0]\n",
      " [48  2]]\n",
      "network nan test after epoch\n",
      "mbi=4480403200\n",
      "epoch 1, global step 4, time 134.339132\n",
      "saving model parameters...\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "On iteration 4\n",
      "Plain evaluation before retrain\n",
      "\tBest top1 validation accuracy: 0.520000\n",
      "\tBest top5 validation accuracy: 0.700000\n",
      "\tBest top1 cumul accuracy: 0.172500\n",
      "\tBest top5 cumul accuracy: 0.740000\n",
      "\tBest top1 ori accuracy: 0.080000\n",
      "\tBest top5 ori accuracy: 0.750000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.16      0.18        50\n",
      "          1       0.00      0.00      0.00        50\n",
      "          2       1.00      0.12      0.21        50\n",
      "          3       0.00      0.00      0.00        50\n",
      "          4       0.60      0.06      0.11        50\n",
      "          5       0.00      0.00      0.00        50\n",
      "          6       0.14      1.00      0.25        50\n",
      "          7       1.00      0.04      0.08        50\n",
      "\n",
      "avg / total       0.37      0.17      0.10       400\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "here\n",
      "augmentation: 2\n",
      "1849 support_vectors for class 0\n",
      "2428 support_vectors for class 1\n",
      "1931 support_vectors for class 2\n",
      "2281 support_vectors for class 3\n",
      "2051 support_vectors for class 4\n",
      "1609 support_vectors for class 5\n",
      "2358 support_vectors for class 6\n",
      "2133 support_vectors for class 7\n",
      "augmentation: 2\n",
      "retraining last layer\n",
      "Epoch 1\n",
      "augmentation: 2\n",
      "Epoch 2\n",
      "augmentation: 2\n",
      "Epoch 3\n",
      "augmentation: 2\n",
      "Epoch 4\n",
      "augmentation: 2\n",
      "Epoch 5\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Plain evaluation after retrain\n",
      "\tBest top1 validation accuracy: 0.120000\n",
      "\tBest top5 validation accuracy: 0.540000\n",
      "\tBest top1 cumul accuracy: 0.302500\n",
      "\tBest top5 cumul accuracy: 0.715000\n",
      "\tBest top1 ori accuracy: 0.490000\n",
      "\tBest top5 ori accuracy: 0.800000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.98      0.34        50\n",
      "          1       0.00      0.00      0.00        50\n",
      "          2       0.68      0.30      0.42        50\n",
      "          3       0.00      0.00      0.00        50\n",
      "          4       0.50      0.36      0.42        50\n",
      "          5       0.39      0.54      0.45        50\n",
      "          6       0.40      0.24      0.30        50\n",
      "          7       0.00      0.00      0.00        50\n",
      "\n",
      "avg / total       0.27      0.30      0.24       400\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "SVM evaluation\n",
      "\tBest top1 validation accuracy: 0.340000\n",
      "\tBest top1 cumul accuracy: 0.520000\n",
      "\tBest top1 ori accuracy: 0.460000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.80      0.67        50\n",
      "          1       0.67      0.12      0.20        50\n",
      "          2       0.42      0.62      0.50        50\n",
      "          3       0.46      0.52      0.49        50\n",
      "          4       0.47      0.64      0.54        50\n",
      "          5       0.64      0.78      0.70        50\n",
      "          6       0.85      0.22      0.35        50\n",
      "          7       0.46      0.46      0.46        50\n",
      "\n",
      "avg / total       0.57      0.52      0.49       400\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Exemplar mean evaluation\n",
      "\tBest top1 validation accuracy: 0.280000\n",
      "\tBest top5 validation accuracy: 0.980000\n",
      "\tBest top1 cumul accuracy: 0.425000\n",
      "\tBest top5 cumul accuracy: 0.890000\n",
      "\tBest top1 ori accuracy: 0.410000\n",
      "\tBest top5 ori accuracy: 0.870000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.58      0.47        50\n",
      "          1       0.50      0.24      0.32        50\n",
      "          2       0.49      0.38      0.43        50\n",
      "          3       0.46      0.52      0.49        50\n",
      "          4       0.52      0.58      0.55        50\n",
      "          5       0.49      0.54      0.51        50\n",
      "          6       0.24      0.10      0.14        50\n",
      "          7       0.31      0.46      0.37        50\n",
      "\n",
      "avg / total       0.42      0.42      0.41       400\n",
      "\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Theoretical mean evaluation\n",
      "\tBest top1 validation accuracy: 0.280000\n",
      "\tBest top5 validation accuracy: 0.980000\n",
      "\tBest top1 cumul accuracy: 0.422500\n",
      "\tBest top5 cumul accuracy: 0.892500\n",
      "\tBest top1 ori accuracy: 0.410000\n",
      "\tBest top5 ori accuracy: 0.870000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.58      0.47        50\n",
      "          1       0.50      0.24      0.32        50\n",
      "          2       0.49      0.38      0.43        50\n",
      "          3       0.46      0.52      0.49        50\n",
      "          4       0.51      0.56      0.53        50\n",
      "          5       0.49      0.54      0.51        50\n",
      "          6       0.24      0.10      0.14        50\n",
      "          7       0.31      0.46      0.37        50\n",
      "\n",
      "avg / total       0.42      0.42      0.41       400\n",
      "\n",
      "===========Final Evaluation=============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation: 2\n",
      "augmentation: 2\n",
      "Final evaluation on all classes (plain method)\n",
      "\tTrain loss: 3.553924\n",
      "\tTrain class loss: 3.497100\n",
      "\tTrain reg loss: 0.174813\n",
      "\tValidation loss: 3.548928\n",
      "\tValidation class loss: 3.492103\n",
      "\tValidation reg loss: 0.056824\n",
      "\tTop1 train accuracy: 0.174813\n",
      "\tTop5 train accuracy: 0.742363\n",
      "\tTop1 validation accuracy: 0.172500\n",
      "\tTop5 validation accuracy: 0.740000\n",
      "augmentation: 2\n",
      "Final evaluation on all classes (Exemplar mean)\n",
      "\tBest top1 validation accuracy: 0.425000\n",
      "\tBest top5 validation accuracy: 0.890000\n",
      "augmentation: 2\n",
      "Final evaluation on all classes (Theoretical mean)\n",
      "\tBest top1 validation accuracy: 0.422500\n",
      "\tBest top5 validation accuracy: 0.892500\n"
     ]
    }
   ],
   "source": [
    "fit(tf_tensors,tf_variables,tf_networks,fixed_params,hyper_params,data_dict_total,sess,resume=False,\n",
    "        save_session=False,save_session_freq=1,save_params=True,evaluation_metric='top1_accuracy',save_history=True,\n",
    "        num_epochs=10,num_iterations=4,verbose=2,print_freq=1,pretrain_evaluation=1,override_warning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='breakhis_Mar21_full_dataset'\n",
    "tf_networks['train_network'].load_model('%s/best_model_params_0.pkl'%base_dir,sess)\n",
    "tf_networks['test_network'].load_model('%s/best_model_params_0.pkl'%base_dir,sess)\n",
    "# with open('%s/theoretical_mean.pkl'%base_dir,'rb') as f:\n",
    "#     theoretical_mean=pickle.load(f)\n",
    "# with open('%s/exemplar_mean.pkl'%base_dir,'rb') as f:\n",
    "#     exemplar_mean=pickle.load(f)\n",
    "# with open('%s/class_ord.json'%base_dir,'r') as f:\n",
    "#     class_ord=json.load(f)\n",
    "plain_evaluation_tensors=dict(loss=tf_tensors['loss_test'],\n",
    "                        class_loss=tf_tensors['class_loss_test'],\n",
    "                        regularization_loss=tf_tensors['top1_accuracy_test'],\n",
    "                        top1_accuracy=tf_tensors['top1_accuracy_test'],\n",
    "                        top5_accuracy=tf_tensors['top5_accuracy_test'],\n",
    "                        X=tf_tensors['X_test'],\n",
    "                        Y=tf_tensors['Y_test'])    \n",
    "test_eval_vals=test_accuracy_evaluation_plain(data_dict_total['X_test'],\n",
    "                                               data_dict_total['Y_test'],\n",
    "                                               hyper_params['test_batch_size'],\n",
    "                                               plain_evaluation_tensors,sess,dataset='breakhis')\n",
    "# feature_map_tensors=dict(X=tf_tensors['X_test'],feature_map=tf_tensors['feature_map_test'])\n",
    "# exemplar_eval_vals=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],\n",
    "#                                        exemplar_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)    \n",
    "# theoretical_eval_vals=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],\n",
    "#                                        theoretical_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "print(test_eval_vals['top1_accuracy'])\n",
    "# print(exemplar_eval_vals['top1_accuracy'])\n",
    "# print(theoretical_eval_vals['top1_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fixed_params['base_dir'],'history.json')) as f:\n",
    "    history_d=json.load(f)\n",
    "plt.plot(range(1,len(history_d[0]['loss_train'])+1),history_d[0]['loss_train'],label='loss train')\n",
    "plt.plot(range(1,len(history_d[0]['loss_test'])+1),history_d[0]['loss_test'],label='loss test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fixed_params['base_dir'],'history.json')) as f:\n",
    "    history_d=json.load(f)\n",
    "plt.plot(range(1,len(history_d[0]['top1_accuracy_train'])+1),history_d[0]['top1_accuracy_train'],label='top1_accuracy train')\n",
    "plt.plot(range(1,len(history_d[0]['top1_accuracy_test'])+1),history_d[0]['top1_accuracy_test'],label='top1_accuracy test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iterate_minibatches_breakhis(data_dict_total['X_train'],data_dict_total['Y_train'],10,augment=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_b[0])\n",
    "plt.gcf().set_size_inches((20,12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

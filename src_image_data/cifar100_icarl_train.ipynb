{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import shutil\n",
    "import inspect\n",
    "from nn_lib import *\n",
    "from train_procedures import *\n",
    "from train_utils import *\n",
    "from cifar100_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "np.random.seed(1997)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict=load_cifar100_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_total=data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params={'beta':1e-5,\n",
    "              'initial_lr':2,\n",
    "              'train_batch_size':128,\n",
    "              'test_batch_size':128,\n",
    "              'lr_reduction_rate':5,\n",
    "              'lr_reduction_epoch':[49,63],\n",
    "              'use_fixedsize_exemplar':True,\n",
    "              'exemplar_set_size':1000,\n",
    "              'final_train_epochs':5,\n",
    "              'se':True,\n",
    "              'primary_exemplar':'svm_exemplar',\n",
    "              'train_method':'train_with_sample_weight',\n",
    "              'sample_weight':1,\n",
    "              'shuffle_class_ord':False,\n",
    "              'optimizer':'momentum',\n",
    "              'ewc_lambda':1e-5,\n",
    "              'loss_function':'softmax_cross_entropy_with_logits'}\n",
    "fixed_params={'dataset':'cifar100',\n",
    "              'net_type':'ResNet32',\n",
    "              'random_seed':1997,\n",
    "              'total_num_classes':10,\n",
    "              'base_dir':'./cifar100_temp',\n",
    "              'class_batch_size':10,\n",
    "              'use_theoretical_mean':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tensors,tf_variables,tf_networks=build_graph(hyper_params,fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "sess=tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_dir': './cifar100_temp',\n",
      " 'class_batch_size': 10,\n",
      " 'dataset': 'cifar100',\n",
      " 'net_type': 'ResNet32',\n",
      " 'random_seed': 1997,\n",
      " 'total_num_classes': 10,\n",
      " 'use_theoretical_mean': True}\n",
      "{'beta': 1e-05,\n",
      " 'ewc_lambda': 1e-05,\n",
      " 'exemplar_set_size': 1000,\n",
      " 'final_train_epochs': 5,\n",
      " 'initial_lr': 2,\n",
      " 'loss_function': 'softmax_cross_entropy_with_logits',\n",
      " 'lr_reduction_epoch': [49, 63],\n",
      " 'lr_reduction_rate': 5,\n",
      " 'optimizer': 'momentum',\n",
      " 'primary_exemplar': 'svm_exemplar',\n",
      " 'sample_weight': 1,\n",
      " 'se': True,\n",
      " 'shuffle_class_ord': False,\n",
      " 'test_batch_size': 128,\n",
      " 'train_batch_size': 128,\n",
      " 'train_method': 'train_with_sample_weight',\n",
      " 'use_fixedsize_exemplar': True}\n",
      "./cifar100_temp already exists, override?y\n",
      "===========Iteration 1=============\n",
      "Using classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class batch pretrain evaluation (plain method)\n",
      "\tTrain loss: 2.695263\n",
      "\tTrain class loss: 2.680719\n",
      "\tTrain reg loss: 0.100000\n",
      "\tValidation loss: 2.705668\n",
      "\tValidation class loss: 2.691124\n",
      "\tValidation reg loss: 0.014544\n",
      "\tTop1 train accuracy: 0.100000\n",
      "\tTop5 train accuracy: 0.503800\n",
      "\tTop1 validation accuracy: 0.100000\n",
      "\tTop5 validation accuracy: 0.500000\n",
      "[[100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]\n",
      " [100   0   0   0   0   0   0   0   0   0]]\n",
      "network nan test after epoch\n",
      "Epoch 1\n",
      "\tTrain loss: 0.232014\n",
      "\tTrain class loss: 0.217259\n",
      "\tTrain reg loss: 0.014755\n",
      "\tValidation loss: 2.980675\n",
      "\tValidation class loss: 2.965708\n",
      "\tValidation reg loss: 0.014967\n",
      "\tTop1 train accuracy: 0.246795\n",
      "\tTop5 train accuracy: 0.734976\n",
      "\tTop1 validation accuracy: 0.265000\n",
      "\tTop5 validation accuracy: 0.769000\n",
      "[[86  2  0  0  1  0  6  1  0  4]\n",
      " [37 19  0 16  3  0  6  1  0 18]\n",
      " [45  1  2  3  8  3  1  0  0 37]\n",
      " [ 1  2  0 36 13  0  0  3  0 45]\n",
      " [ 1  2  0 22 29  3  0  2  1 40]\n",
      " [24  0  2  7 11  6  1  0  1 48]\n",
      " [28  0  2  7  6  1 14  3  0 39]\n",
      " [19  1  3  8  6  2  2  7  0 52]\n",
      " [ 6  0  0 17  7  0  0  2  0 68]\n",
      " [14  0  0 11  3  1  2  3  0 66]]\n",
      "epoch 1, global step 1, time 10.638997\n",
      "saving model parameters...\n",
      "On iteration 1\n",
      "Plain evaluation before retrain\n",
      "\tBest top1 validation accuracy: 0.265000\n",
      "\tBest top5 validation accuracy: 0.769000\n",
      "\tBest top1 cumul accuracy: 0.265000\n",
      "\tBest top5 cumul accuracy: 0.769000\n",
      "\tBest top1 ori accuracy: 0.265000\n",
      "\tBest top5 ori accuracy: 0.769000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.86      0.48       100\n",
      "          1       0.70      0.19      0.30       100\n",
      "          2       0.22      0.02      0.04       100\n",
      "          3       0.28      0.36      0.32       100\n",
      "          4       0.33      0.29      0.31       100\n",
      "          5       0.38      0.06      0.10       100\n",
      "          6       0.44      0.14      0.21       100\n",
      "          7       0.32      0.07      0.11       100\n",
      "          8       0.00      0.00      0.00       100\n",
      "          9       0.16      0.66      0.26       100\n",
      "\n",
      "avg / total       0.32      0.27      0.21      1000\n",
      "\n",
      "retraining last layer\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Plain evaluation after retrain\n",
      "\tBest top1 validation accuracy: 0.396000\n",
      "\tBest top5 validation accuracy: 0.852000\n",
      "\tBest top1 cumul accuracy: 0.396000\n",
      "\tBest top5 cumul accuracy: 0.852000\n",
      "\tBest top1 ori accuracy: 0.396000\n",
      "\tBest top5 ori accuracy: 0.852000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66       100\n",
      "          1       0.56      0.49      0.52       100\n",
      "          2       0.43      0.30      0.36       100\n",
      "          3       0.37      0.41      0.39       100\n",
      "          4       0.32      0.49      0.39       100\n",
      "          5       0.27      0.50      0.35       100\n",
      "          6       0.47      0.29      0.36       100\n",
      "          7       0.27      0.29      0.28       100\n",
      "          8       0.41      0.26      0.32       100\n",
      "          9       0.46      0.25      0.32       100\n",
      "\n",
      "avg / total       0.42      0.40      0.39      1000\n",
      "\n",
      "SVM evaluation\n",
      "\tBest top1 validation accuracy: 0.388000\n",
      "\tBest top1 cumul accuracy: 0.388000\n",
      "\tBest top1 ori accuracy: 0.388000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.73      0.66       100\n",
      "          1       0.61      0.46      0.52       100\n",
      "          2       0.42      0.27      0.33       100\n",
      "          3       0.31      0.42      0.36       100\n",
      "          4       0.33      0.54      0.41       100\n",
      "          5       0.43      0.41      0.42       100\n",
      "          6       0.44      0.35      0.39       100\n",
      "          7       0.26      0.05      0.08       100\n",
      "          8       0.24      0.53      0.33       100\n",
      "          9       0.52      0.12      0.20       100\n",
      "\n",
      "avg / total       0.41      0.39      0.37      1000\n",
      "\n",
      "Exemplar mean evaluation\n",
      "\tBest top1 validation accuracy: 0.243000\n",
      "\tBest top5 validation accuracy: 0.719000\n",
      "\tBest top1 cumul accuracy: 0.243000\n",
      "\tBest top5 cumul accuracy: 0.719000\n",
      "\tBest top1 ori accuracy: 0.243000\n",
      "\tBest top5 ori accuracy: 0.719000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.31      0.43       100\n",
      "          1       0.36      0.15      0.21       100\n",
      "          2       0.33      0.13      0.19       100\n",
      "          3       0.27      0.25      0.26       100\n",
      "          4       0.23      0.78      0.35       100\n",
      "          5       0.15      0.08      0.10       100\n",
      "          6       0.28      0.22      0.25       100\n",
      "          7       0.11      0.05      0.07       100\n",
      "          8       0.18      0.46      0.26       100\n",
      "          9       0.00      0.00      0.00       100\n",
      "\n",
      "avg / total       0.26      0.24      0.21      1000\n",
      "\n",
      "Theoretical mean evaluation\n",
      "\tBest top1 validation accuracy: 0.362000\n",
      "\tBest top5 validation accuracy: 0.839000\n",
      "\tBest top1 cumul accuracy: 0.362000\n",
      "\tBest top5 cumul accuracy: 0.839000\n",
      "\tBest top1 ori accuracy: 0.362000\n",
      "\tBest top5 ori accuracy: 0.839000\n",
      "\tReport string of cumul dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.67      0.59       100\n",
      "          1       0.55      0.39      0.46       100\n",
      "          2       0.37      0.20      0.26       100\n",
      "          3       0.33      0.40      0.36       100\n",
      "          4       0.32      0.49      0.38       100\n",
      "          5       0.40      0.37      0.39       100\n",
      "          6       0.40      0.32      0.35       100\n",
      "          7       0.18      0.09      0.12       100\n",
      "          8       0.25      0.50      0.33       100\n",
      "          9       0.43      0.19      0.26       100\n",
      "\n",
      "avg / total       0.37      0.36      0.35      1000\n",
      "\n",
      "===========Final Evaluation=============\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "flat indices[127, :] = [127, 10] does not index into param (shape: [128,10]).\n\t [[Node: GatherNd_1 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](TopKV2_3/_1761, stack_1/_1763)]]\n\t [[Node: GatherNd_1/_1765 = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_2329_GatherNd_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'GatherNd_1', defined at:\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-6626b12dcd72>\", line 1, in <module>\n    tf_tensors,tf_variables,tf_networks=build_graph(hyper_params,fixed_params)\n  File \"/home/test_user/IL/myIL/train_procedures.py\", line 138, in build_graph\n    ranks_of_groud_truth_class_test=fixed_params['total_num_classes']-1-tf.gather_nd(ranks_of_indices_test,indexing_matrix_test)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in gather_nd\n    name=name)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): flat indices[127, :] = [127, 10] does not index into param (shape: [128,10]).\n\t [[Node: GatherNd_1 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](TopKV2_3/_1761, stack_1/_1763)]]\n\t [[Node: GatherNd_1/_1765 = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_2329_GatherNd_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: flat indices[127, :] = [127, 10] does not index into param (shape: [128,10]).\n\t [[Node: GatherNd_1 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](TopKV2_3/_1761, stack_1/_1763)]]\n\t [[Node: GatherNd_1/_1765 = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_2329_GatherNd_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-099d8283a1d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fit(tf_tensors,tf_variables,tf_networks,fixed_params,hyper_params,data_dict,sess,resume=False,\n\u001b[1;32m      2\u001b[0m         \u001b[0msave_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_session_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluation_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'top1_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         num_epochs=1,num_iterations=1,verbose=2,print_freq=1,pretrain_evaluation=1,override_warning=True)\n\u001b[0m",
      "\u001b[0;32m~/IL/myIL/train_procedures.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(tf_tensors, tf_variables, tf_networks, fixed_params, hyper_params, data_dict_total, session, resume, save_session, save_session_freq, save_params, evaluation_metric, save_history, num_epochs, num_iterations, verbose, print_freq, pretrain_evaluation, override_warning)\u001b[0m\n\u001b[1;32m    930\u001b[0m                                                    \u001b[0mdata_dict_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                                                    \u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                                                    plain_evaluation_tensors,session,dataset=dataset)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mtf_log_var_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mevaluation_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation_vals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IL/myIL/train_utils.py\u001b[0m in \u001b[0;36mtest_accuracy_evaluation_plain\u001b[0;34m(X_test, Y_test, test_batch_size, evaluation_tensors, session, dataset)\u001b[0m\n\u001b[1;32m     80\u001b[0m         session.run([evaluation_tensors['loss'],evaluation_tensors['class_loss'],evaluation_tensors['regularization_loss'],evaluation_tensors['top1_accuracy'],evaluation_tensors['top5_accuracy'],evaluation_tensors['fc']],\n\u001b[1;32m     81\u001b[0m                     feed_dict={evaluation_tensors['X']:X_minibatch,\n\u001b[0;32m---> 82\u001b[0;31m                                evaluation_tensors['Y']:Y_minibatch})\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_minibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mevaluation_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlocal_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: flat indices[127, :] = [127, 10] does not index into param (shape: [128,10]).\n\t [[Node: GatherNd_1 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](TopKV2_3/_1761, stack_1/_1763)]]\n\t [[Node: GatherNd_1/_1765 = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_2329_GatherNd_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'GatherNd_1', defined at:\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-6626b12dcd72>\", line 1, in <module>\n    tf_tensors,tf_variables,tf_networks=build_graph(hyper_params,fixed_params)\n  File \"/home/test_user/IL/myIL/train_procedures.py\", line 138, in build_graph\n    ranks_of_groud_truth_class_test=fixed_params['total_num_classes']-1-tf.gather_nd(ranks_of_indices_test,indexing_matrix_test)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in gather_nd\n    name=name)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/test_user/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): flat indices[127, :] = [127, 10] does not index into param (shape: [128,10]).\n\t [[Node: GatherNd_1 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](TopKV2_3/_1761, stack_1/_1763)]]\n\t [[Node: GatherNd_1/_1765 = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_2329_GatherNd_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "fit(tf_tensors,tf_variables,tf_networks,fixed_params,hyper_params,data_dict,sess,resume=False,\n",
    "        save_session=False,save_session_freq=1,save_params=True,evaluation_metric='top1_accuracy',save_history=True,\n",
    "        num_epochs=1,num_iterations=1,verbose=2,print_freq=1,pretrain_evaluation=1,override_warning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx=np.array([i in [45, 76, 92, 44, 34, 6, 9, 80, 20, 48] for i in data_dict['Y_train']])\n",
    "test_idx=np.array([i in [45, 76, 92, 44, 34, 6, 9, 80, 20, 48] for i in data_dict['Y_test']])\n",
    "X_train_c=data_dict['X_train'][train_idx]\n",
    "Y_train_c=data_dict['Y_train'][train_idx]\n",
    "X_test_c=data_dict['X_test'][test_idx]\n",
    "Y_test_c=data_dict['Y_test'][test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_tensors=dict(X=tf_tensors['X_test'],feature_map=tf_tensors['feature_map_test'])\n",
    "feature_maps_train=test_get_feature_maps(X_train_c,128,feature_map_tensors,sess,dataset='cifar100')\n",
    "feature_maps_test=test_get_feature_maps(X_test_c,128,feature_map_tensors,sess,dataset='cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=svm_retrain_with_exemplars(exemplar,[45, 76, 92, 44, 34, 6, 9, 80, 20, 48],128,feature_map_tensors,sess,dataset='cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm=test_prediction_svm(X_test_c,128,feature_map_tensors,svm,sess,dataset='cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_svm==Y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([0,svm.n_support_]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='cifar100_icarl_debug_Mar13_icarl_70epoch'\n",
    "with open('%s/exemplar.pkl'%base_dir,'rb') as f:\n",
    "    exemplar=pickle.load(f)\n",
    "exemplars_up_to_now=exemplar.reshape(-1,32,32,3)\n",
    "exemplars_up_to_now_label=np.tile(np.arange(100).reshape(100,1),[1,50]).reshape(-1,1).squeeze()\n",
    "rand_idx=np.arange(5000)\n",
    "np.random.shuffle(rand_idx)\n",
    "exemplars_up_to_now=exemplars_up_to_now[rand_idx[:]]\n",
    "exemplars_up_to_now_label=exemplars_up_to_now_label[rand_idx[:]]\n",
    "\n",
    "# train_tensors=copy(tf_tensors)\n",
    "# train_tensors['optimizer_train']=\\\n",
    "# tf.train.AdamOptimizer().\\\n",
    "# minimize(tf_tensors['loss_train'],var_list=[tf_networks['train_network'].tf_variables['fc/W'],\n",
    "#                                             tf_networks['train_network'].tf_variables['fc/b']])\n",
    "# tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_networks['train_network'].load_model('%s/best_model_params_9.pkl'%base_dir,sess)\n",
    "tf_networks['test_network'].load_model('%s/best_model_params_9.pkl'%base_dir,sess)\n",
    "with open('%s/theoretical_mean.pkl'%base_dir,'rb') as f:\n",
    "    theoretical_mean=pickle.load(f)\n",
    "with open('%s/exemplar_mean.pkl'%base_dir,'rb') as f:\n",
    "    exemplar_mean=pickle.load(f)\n",
    "with open('%s/class_ord.json'%base_dir,'r') as f:\n",
    "    class_ord=json.load(f)\n",
    "plain_evaluation_tensors=dict(loss=tf_tensors['loss_test'],\n",
    "                        class_loss=tf_tensors['class_loss_test'],\n",
    "                        regularization_loss=tf_tensors['top1_accuracy_test'],\n",
    "                        top1_accuracy=tf_tensors['top1_accuracy_test'],\n",
    "                        top5_accuracy=tf_tensors['top5_accuracy_test'],\n",
    "                        X=tf_tensors['X_test'],\n",
    "                        Y=tf_tensors['Y_test'])    \n",
    "test_eval_vals=test_accuracy_evaluation_plain(data_dict_total['X_test'],\n",
    "                                               data_dict_total['Y_test'],\n",
    "                                               hyper_params['test_batch_size'],\n",
    "                                               plain_evaluation_tensors,sess)\n",
    "feature_map_tensors=dict(X=tf_tensors['X_test'],feature_map=tf_tensors['feature_map_test'])\n",
    "exemplar_eval_vals=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],\n",
    "                                       exemplar_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)    \n",
    "theoretical_eval_vals=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],\n",
    "                                       theoretical_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "print(test_eval_vals['top1_accuracy'])\n",
    "print(exemplar_eval_vals['top1_accuracy'])\n",
    "print(theoretical_eval_vals['top1_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_retrain_with_exemplars(exemplar,class_ord,128,\n",
    "                                      tf_tensors,tf_networks['train_network'],'%s/best_model_params_9.pkl'%base_dir,5,session=sess,dataset='cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(5):\n",
    "#     print('Epoch %d'%(epoch+1))\n",
    "#     train_eval_vals=train_plain(exemplars_up_to_now,exemplars_up_to_now_label,hyper_params['train_batch_size'],train_tensors,sess)\n",
    "  \n",
    "tf_networks['test_network'].set_model_params(tf_networks['train_network'].get_all_model_params())\n",
    "plain_evaluation_tensors=dict(loss=tf_tensors['loss_test'],\n",
    "                        class_loss=tf_tensors['class_loss_test'],\n",
    "                        regularization_loss=tf_tensors['top1_accuracy_test'],\n",
    "                        top1_accuracy=tf_tensors['top1_accuracy_test'],\n",
    "                        top5_accuracy=tf_tensors['top5_accuracy_test'],\n",
    "                        X=tf_tensors['X_test'],\n",
    "                        Y=tf_tensors['Y_test'])    \n",
    "test_eval_vals=test_accuracy_evaluation_plain(data_dict_total['X_test'],\n",
    "                                               data_dict_total['Y_test'],\n",
    "                                               hyper_params['test_batch_size'],\n",
    "                                               plain_evaluation_tensors,sess)\n",
    "feature_map_tensors=dict(X=tf_tensors['X_test'],feature_map=tf_tensors['feature_map_test'])\n",
    "update_exemplar_mean(exemplar_mean,exemplar,fixed_params['class_batch_size'],hyper_params['test_batch_size'],9,class_ord,feature_map_tensors,sess)\n",
    "exemplar_eval_vals=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],\n",
    "                                       exemplar_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)    \n",
    "update_theoretical_mean(theoretical_mean,data_dict_total['X_train'],data_dict_total['Y_train'],fixed_params['class_batch_size'],hyper_params['test_batch_size'],9,class_ord,feature_map_tensors,sess)\n",
    "theoretical_eval_vals=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],\n",
    "                                       theoretical_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "print(test_eval_vals['top1_accuracy'])\n",
    "print(exemplar_eval_vals['top1_accuracy'])\n",
    "print(theoretical_eval_vals['top1_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='cifar100_icarl_debug_Mar13_icarl_70epoch'\n",
    "\n",
    "with open('%s/class_ord.json'%base_dir,'r') as f:\n",
    "    class_ord=json.load(f)\n",
    "row_order=np.array(class_ord)[:,np.newaxis]\n",
    "col_order=np.array(class_ord)[np.newaxis,:]\n",
    "#tf_networks['test_network'].load_model('%s/best_model_params_9.pkl'%base_dir,sess)\n",
    "plain_evaluation_tensors=dict(loss=tf_tensors['loss_test'],\n",
    "                        class_loss=tf_tensors['class_loss_test'],\n",
    "                        regularization_loss=tf_tensors['top1_accuracy_test'],\n",
    "                        top1_accuracy=tf_tensors['top1_accuracy_test'],\n",
    "                        top5_accuracy=tf_tensors['top5_accuracy_test'],\n",
    "                        X=tf_tensors['X_test'],\n",
    "                        Y=tf_tensors['Y_test'],\n",
    "                        fc=tf_networks['test_network'].tf_tensors['fc'])    \n",
    "eval_plain=test_accuracy_evaluation_plain(data_dict_total['X_test'],\n",
    "                                               data_dict_total['Y_test'],\n",
    "                                               hyper_params['test_batch_size'],\n",
    "                                               plain_evaluation_tensors,sess)\n",
    "pred_plain=test_prediction_plain(data_dict_total['X_test'],hyper_params['test_batch_size'],plain_evaluation_tensors,sess)\n",
    "mat1=confusion_matrix(data_dict_total['Y_test'],pred_plain)[row_order,col_order]\n",
    "sns.heatmap(mat1,cmap='bwr',vmin=0,vmax=100)\n",
    "plt.gcf().set_size_inches((15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_ncm==data_dict_total['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ord.index(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=pickle.load(open('%s/best_model_params_9.pkl'%base_dir,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['conv_1/W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='cifar100_icarl_debug_Mar13_icarl_70epoch'\n",
    "with open('%s/theoretical_mean.pkl'%base_dir,'rb') as f:\n",
    "    theoretical_mean=pickle.load(f)\n",
    "with open('%s/exemplar_mean.pkl'%base_dir,'rb') as f:\n",
    "    exemplar_mean=pickle.load(f)\n",
    "with open('%s/class_ord.json'%base_dir,'r') as f:\n",
    "    class_ord=json.load(f)\n",
    "row_order=np.array(class_ord)[:,np.newaxis]\n",
    "col_order=np.array(class_ord)[np.newaxis,:]\n",
    "tf_networks['test_network'].load_model('%s/best_model_params_9.pkl'%base_dir,sess)\n",
    "evaluation_tensors={'X':tf_tensors['X_test'],'fc':tf_networks['test_network'].tf_tensors['fc']}\n",
    "eval_ncm=test_accuracy_evaluation_ncm(data_dict_total['X_test'],data_dict_total['Y_test'],exemplar_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "pred_ncm=test_prediction_ncm(data_dict_total['X_test'],exemplar_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "mat1=confusion_matrix(data_dict_total['Y_test'],pred_ncm)[row_order,col_order]\n",
    "sns.heatmap(mat1,cmap='bwr',vmin=0,vmax=100)\n",
    "plt.gcf().set_size_inches((15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravel_ord=mat1.ravel().argsort()\n",
    "inter_class_batch_cumsum=0\n",
    "for i in range(len(ravel_ord)-1,-1,-1):\n",
    "    row,col=np.unravel_index(ravel_ord[i],mat1.shape)\n",
    "    row_batch,col_batch=int(class_ord.index(row)/10),int(class_ord.index(col)/10)\n",
    "    if row_batch!=col_batch:\n",
    "        inter_class_batch_cumsum+=mat1[row,col]\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.trace(mat1)/(np.sum(mat1)-np.trace(mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cifar100_icarl_debug_Mar13_icarl_70epoch\n",
    "history1=json.load(open('cifar100_icarl_debug_Mar13_icarl_70epoch/history.json'))\n",
    "history2=json.load(open('cifar100_icarl_debug_Mar14_plain_70epoch/history.json'))\n",
    "history3=json.load(open('cifar100_icarl_debug_Mar15_sample_weight_70epoch/history.json'))\n",
    "history4=json.load(open('cifar100_icarl_debug_Mar15_distillation_and_ground_truth_70epoch/history.json'))\n",
    "history5=json.load(open('cifar100_icarl_debug_Mar16_sample_weight_exemplar_by_loss_70epoch/history.json'))\n",
    "plt.plot(range(1,11),[history1[i]['best_top1_accuracy_exemplar_mean_cumul'] for i in range(10)],label='history1')\n",
    "plt.plot(range(1,11),[history2[i]['best_top1_accuracy_exemplar_mean_cumul'] for i in range(10)],label='history2')\n",
    "plt.plot(range(1,11),[history3[i]['best_top1_accuracy_exemplar_mean_cumul'] for i in range(10)],label='history3')\n",
    "plt.plot(range(1,11),[history4[i]['best_top1_accuracy_exemplar_mean_cumul'] for i in range(10)],label='history4')\n",
    "plt.plot(range(1,11),[history5[i]['best_top1_accuracy_exemplar_mean_cumul'] for i in range(10)],label='history5')\n",
    "plt.ylim([0.3,1])\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(range(1,11),[history1[i]['best_top1_accuracy_exemplar_mean_test'] for i in range(10)],label='history1')\n",
    "plt.plot(range(1,11),[history2[i]['best_top1_accuracy_exemplar_mean_test'] for i in range(10)],label='history2')\n",
    "plt.plot(range(1,11),[history3[i]['best_top1_accuracy_exemplar_mean_test'] for i in range(10)],label='history3')\n",
    "plt.plot(range(1,11),[history4[i]['best_top1_accuracy_exemplar_mean_test'] for i in range(10)],label='history4')\n",
    "plt.plot(range(1,11),[history5[i]['best_top1_accuracy_exemplar_mean_test'] for i in range(10)],label='history5')\n",
    "plt.ylim([0.3,1])\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(range(1,11),[history1[i]['best_top1_accuracy_exemplar_mean_ori'] for i in range(10)],label='history1')\n",
    "plt.plot(range(1,11),[history2[i]['best_top1_accuracy_exemplar_mean_ori'] for i in range(10)],label='history2')\n",
    "plt.plot(range(1,11),[history3[i]['best_top1_accuracy_exemplar_mean_ori'] for i in range(10)],label='history3')\n",
    "plt.plot(range(1,11),[history4[i]['best_top1_accuracy_exemplar_mean_ori'] for i in range(10)],label='history4')\n",
    "plt.plot(range(1,11),[history5[i]['best_top1_accuracy_exemplar_mean_ori'] for i in range(10)],label='history5')\n",
    "plt.ylim([0.3,1])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mat=confusion_matrix(data_dict_total['Y_test'],pred_ncm)\n",
    "sns.heatmap(mat,cmap='bwr',vmin=0,vmax=100)\n",
    "plt.gcf().set_size_inches((15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fixed_params['base_dir'],'history.json')) as f:\n",
    "    history_d=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(history_d[0]['loss_train'])+1),history_d[0]['loss_train'])\n",
    "plt.plot(range(1,len(history_d[0]['loss_test'])+1),history_d[0]['loss_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(history_d[0]['top1_accuracy_train'])+1),history_d[0]['top1_accuracy_train'])\n",
    "plt.plot(range(1,len(history_d[0]['top1_accuracy_test'])+1),history_d[0]['top1_accuracy_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc_exem_mean=[history_d[i]['best_top1_accuracy_exemplar_mean_test'] for i in range(10)]\n",
    "top1_acc_theo_mean=[history_d[i]['best_top1_accuracy_theoretical_mean_test'] for i in range(10)]\n",
    "top1_acc_plain=[history_d[i]['best_top1_accuracy_plain_test'] for i in range(10)]\n",
    "plt.plot(range(1,len(top1_acc_exem_mean)+1),top1_acc_exem_mean,label='top1_acc_exem_mean')\n",
    "plt.plot(range(1,len(top1_acc_theo_mean)+1),top1_acc_theo_mean,label='top1_acc_theo_mean')\n",
    "plt.plot(range(1,len(top1_acc_plain)+1),top1_acc_plain,label='top1_acc_plain')\n",
    "plt.legend()\n",
    "plt.ylim([0,1])\n",
    "plt.gcf().set_size_inches((15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fixed_params['base_dir'],'theoretical_mean.pkl'),'rb') as f:\n",
    "    theoretical_mean=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fixed_params['base_dir'],'exemplar_mean.pkl'),'rb') as f:\n",
    "    exemplar_mean=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fixed_params['base_dir'],'exemplar.pkl'),'rb') as f:\n",
    "    exemplar=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(exemplar[0,5,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isnan(np.array([np.nan,np.nan])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar[1,:,...]==exemplar[1,0:1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(exemplar_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(theoretical_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_mean[0].dot(exemplar_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_d['global_step'],history_d['loss_train'],label='loss_train')\n",
    "plt.plot(history_d['global_step'],history_d['loss_test'],label='loss_test')\n",
    "plt.plot(history_d2['global_step'],history_d2['loss_train'],label='loss_train2')\n",
    "plt.plot(history_d2['global_step'],history_d2['loss_test'],label='loss_test2')\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches((30,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_d['global_step'],history_d['top1_accuracy_train'],label='loss_train')\n",
    "plt.plot(history_d['global_step'],history_d['top1_accuracy_test'],label='loss_test')\n",
    "plt.plot(history_d2['global_step'],history_d2['top1_accuracy_train'],label='top1_accuracy_train2')\n",
    "plt.plot(history_d2['global_step'],history_d2['top1_accuracy_test'],label='top1_accuracy_test2')\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches((30,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train=sess.run(tf_tensors['loss_train'],feed_dict={tf_tensors['X_train']:X_test_c,tf_tensors['Y_train']:Y_test_c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_networks['test_network'].set_model_params(tf_networks['train_network'].get_all_model_params(sess),sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test=sess.run(tf_networks['test_network'].tf_tensors['fc'],feed_dict={tf_tensors['X_test']:X_test_c,tf_tensors['Y_test']:Y_test_c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_mean=pickle.load(open('cifar100_icarl_debug_Mar11_2/theoretical_mean.pkl','rb'))\n",
    "feature_map_tensors=dict(X=tf_tensors['X_test'],feature_map=tf_tensors['feature_map_test'])\n",
    "eval_vals=test_accuracy_evaluation_ncm(X_test_c,Y_test_c,\n",
    "        theoretical_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "eval_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_mean=pickle.load(open('cifar100_icarl_debug_Mar11_2/exemplar_mean.pkl','rb'))\n",
    "feature_map_tensors=dict(X=tf_tensors['X_test'],feature_map=tf_tensors['feature_map_test'])\n",
    "eval_vals=test_accuracy_evaluation_ncm(X_test_c,Y_test_c,\n",
    "        exemplar_mean,hyper_params['test_batch_size'],feature_map_tensors,sess)\n",
    "eval_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_10=load_cifar10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=unpickle(CIFAR10_META_FILE,encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train=sess.run(tf_tensors['ranks_of_groud_truth_class_train'],feed_dict={tf_tensors['X_train']:X_train_c,\n",
    "                                                                  tf_tensors['Y_train']:Y_train_c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test=sess.run(tf_tensors['ranks_of_groud_truth_class_test'],feed_dict={tf_tensors['X_test']:X_test_c,\n",
    "                                                                  tf_tensors['Y_test']:Y_test_c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score_train<5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope='ResNet32_train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf.get_collection(tf.GraphKeys.WEIGHTS, scope='ResNet32_train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v.shape.as_list() for v in tf_networks['train_network'].tf_variables.values() if v.name.endswith('W:0') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=sess.run(tf_tensors['ranks_of_groud_truth_class_test'],feed_dict={tf_tensors['X_test']:X_test_c[:],\n",
    "                                                                  tf_tensors['Y_test']:Y_test_c[:]})\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_log_var_val={}\n",
    "tf_log_var_val['loss_test']=0\n",
    "tf_log_var_val['top1_accuracy_test']=0\n",
    "tf_log_var_val['top5_accuracy_test']=0\n",
    "tf_log_var_val['correct_prediction']=0\n",
    "num_batches_test=int((np.sum(test_idx)/hyper_params['test_batch_size']))\n",
    "model_params=tf_networks['train_network'].get_all_model_params(sess)\n",
    "for X_minibatch,Y_minibatch in iterate_minibatches(X_test_c,Y_test_c,hyper_params['test_batch_size'],shuffle=False):\n",
    "    local_loss,local_top1_accuracy_test,local_top5_accuracy_test,local_ranks_of_groud_truth_class_test=\\\n",
    "    sess.run([tf_tensors['loss_test'],tf_tensors['top1_accuracy_test'],tf_tensors['top5_accuracy_test'],tf_tensors['ranks_of_groud_truth_class_test']],\n",
    "                feed_dict={tf_tensors['X_test']:X_minibatch,\n",
    "                           tf_tensors['Y_test']:Y_minibatch})\n",
    "\n",
    "    tf_log_var_val['loss_test']+=local_loss/num_batches_test\n",
    "    tf_log_var_val['top1_accuracy_test']+=local_top1_accuracy_test/num_batches_test\n",
    "    tf_log_var_val['top5_accuracy_test']+=local_top5_accuracy_test/num_batches_test\n",
    "    tf_log_var_val['correct_prediction']+=np.sum(local_ranks_of_groud_truth_class_test<5)\n",
    "    print(local_ranks_of_groud_truth_class_test)\n",
    "print('Pretrain evaluation')\n",
    "print(\"\\tValidation loss: %f\"%(tf_log_var_val['loss_test']))\n",
    "print(\"\\tTop1 validation accuracy: %f\"%(tf_log_var_val['top1_accuracy_test']))\n",
    "print(\"\\tTop5 validation accuracy: %f\"%(tf_log_var_val['top5_accuracy_test']))\n",
    "print(\"\\tCorrect prediction: %d\"%(tf_log_var_val['correct_prediction']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
